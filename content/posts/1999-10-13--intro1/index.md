---
title: 人工知能から人工無脳へ(1999年)
category: "アーカイブ"
cover: image0.jpg
author: 加藤真一
---

話し相手になる機械、心をもった人工物。まるで人類に与えられた使命のように、その登場を私たちは神話の時代から絶えることなく渇望してきた。コンピュータの登場、そして人工知能技術の開花によってそれらはいよいよ現実になるかと人々を熱狂させた。しかし現実には人工知能の研究は心の機構についてほとんど何も説明できなかった。人工知能として実装するということは心そのものをプログラムの言葉で記述することなのであるが、そもそも**記述不可能な領域**が心には多すぎるというのが代表的な批判を展開したM.MinskyやDreyfusらの考え方である。  

Dreyfus1は"Mind Over Machine"[^1]のなかで初心者→経験を積んだ初心者→中級者→上級者→エキスパートという、初心者からエキスパートにいたる５つの段階を例にあげて説明している。自転車に乗ることを考えてみよう。自転車乗りの初心者は、まず倒れず走ることに精一杯である。ハンドルの切りすぎでまっすぐに走れない。カーブを曲がり損ねて倒れる、と体験を積み重ねるにつれ初心者はルールを発見し、あるいは教えてもらって自転車に乗れるようになる。上級者は自分の自転車を思うように制御でき、運転するための多くのルールを知っている。ところがエキスパートになると初心者のころに考えた、倒れないための制御ルールとかカーブのきつさと適切な操舵角の関係などを意識しない。単に地図上を歩行よりも速い速度で移動するというレベルになってしまい、運転者の意識はどのルートがいいかとか、目的地で何をするかとかいったことに向いてしまう。  

エキスパートが暗黙のうちに適用しているこのルールを明文化する試みはほとんど成功しなかった[^2]。そして運転に限らず、意思決定、ひらめき、好き嫌いなど我々の思考の大部分はそうした明文化できないルールから成り立っていると考えられるのである。  

もうひとつの大きな問題は意味の理解である。チェスのようにあらかじめプログラムに理解できる形式で表現された知識の操作についてはいくつもの大きな成果がある。A. Newell, H. Simon, J. C. ShawらのLogic Theolist, Genaral Problem Solver (GPS), Production System, Truth Maintenance System (TMS)などのように。 しかし自然言語をプログラムに理解できる形式に変換する手法の問題と世界自体をどのように表現するかという問題はいまだに解決されていない。自然言語解釈といえば日本語では形態素解析[^3]がそれにあたると考えている向きもある。英語は便利なことに単語がスペースで区切られているのだが、日本語のようにトークンの切れ目がはっきりしない言語の場合は言葉を送り仮名や格変化も含めて文節化や品詞分解を前処理として行わなければならない。このような形態素解析や、人工知能の分野で用いられるようなさらに進んださまざまな構文解析は確かに意味理解を実現するための必要条件かもしれないが、それだけでは十分ではない。自然言語、特に話し言葉では相手に伝えたい意味のうち暗黙の了解が成立している部分はしゃべらない。

> A：「B君は家にいるかな？」
>
> C：「今日は天気がいいですから」

このやりとりで**C**は**A**の質問に対してyesともnoとも言っていないが、**B**の性格を両者が知っているという暗黙の了解のもとに、問題なく会話は通じている。せりふに何通りもの解釈が可能になって絞り込めない点も大きな問題であるが、共通の背景を持って始めて意味が理解できるわけで、すなわちプログラムも内部に記述された世界を持っていなければ**意味は理解できない**というわけである。情報系学科の学生が化学の専門講義の部屋に間違って入ってしまったことを想像してみよう。たとえばこんな調子である。「PANの代わりにTANやTARを用いると、TANあるいはTARの銅キレートはEDTAとの置換反応が速いので・・・。」日本語だということはわかっても飛び交う専門用語、その業界の常識など知らなければ意味は理解できない。もちろん人間はプログラムよりもよほど正確に形態素解析ができるのにもかかわらず、である。結局形態素解析は意味の理解に寄与しないというわけであるが、形態素解析の何が間違っていたのだろうか？それは言語と思考を切り離してしまった点にある。思考から乖離した言語は意味を失ってしまうのである。このタイプの間違いは人工無脳業界にはつき物なのであるが、人間は複雑なシステムに記述可能な部分とブラックボックス的部分を見出すと、その区別が全体の構成の中で正しいかどうかを置き去りにしてまず切り分けてしまい、逆にそれを根拠として全体を再構成しようと試みてしまうのである。  
  
さてつぎに世界の記述に目を向けてみよう。ここで取り上げるのはフレーム問題[^4] と学習問題である。フレーム問題の本質は**可能性爆発**で、疑問点はなぜ人間は可能性爆発に陥らないのか、いうことである。一冊の辞典を渡され、「牛という言葉について辞書を引いて教えてください」という課題を与えられた生徒を考えてみよう。生徒は最初に『牛』を引くだろう。牛の項にはそれが哺乳類であること、牛乳を生産すること、ことわざに用いられていることなどが記載されていて、哺乳類とは何か、牛乳とは何か、のようにわからない言葉を生徒は再帰的に調べることになる。ところが先生は目の前で答えを待っているのであらゆる未知の言葉を調べ尽くすことはできず、生徒はほどほどのところで調査を打ち切って回答してしまう。もちろん枝葉末節の言葉になるほど例え意味がわかっても『牛』の概念を説明するときにはほとんど意味がなくなるだろう。しかしここで考えてみると、辞書の中でこれまでに調べた項目以外の内容で牛について述べている項目がないことを確かめたわけではない。いやまて、この辞書には無いことが別の辞書には載っているかもしれない。かくしてプログラムは辞書をしらみつぶしに読み始め、牛という言葉がそれ以上辞書に出てこないことを証明するまで吟味をあきらめない。幸いなことに辞書には終わりがあるが、現実の問題には終わりがあるだろうか？これがフレーム問題と呼ばれる、選択肢が多くなりすぎることによる処理の行き詰まりである。  

生徒はなぜフレーム問題を起こさないのだろうか？生徒の飽きっぽさに一つの原因があるだろう。飽きっぽいというのは別に悪いことではない。システムとしての人間にとってそれは重要な危機回避の機構なのである。飽きる、というのはその人にとって変化がなくなったことを意味する。生徒は辞書を引く行為自体に飽きたり、辞書引いて出てくる言葉が当初の問題である「牛」の概念を変化させなくなることによって飽きたり、さらには授業が自分の知識にとって何の刺激にもならなくなることによって飽きる。プログラムにこうした判断ができないのは、現在の懸案が当初のテーマに対してどれほど重要かを評価できないことによる。   

世界の記述にきりがないという話はわかった。現実には記述できる量は有限なのだし何らかの歯止めを用意すれば回避でききるかもしれない。しかしその世界の記述はどうやって用意するのだろうか？もちろんプログラマが教え込むことはできる。しかしプログラマもまた飽きっぽいためにすべてのルールを教えることは不可能である。常に変化する状況、新しい状況に対応するためには人工知能は自分でルールを獲得しなければならない。現在手持ちのルールで失敗した場合は同じ失敗を繰り返さないようにしなければならない。それゆえ学習は必要になるのであるが、そこには可能性爆発以上に難しいハードルが待ち受けている。それはルールを作るルールが作れていないということであり、疑問は自然と、どうやって人間はルールを作っているのかということに向く。  

人間がルールを作る方法については幾多の仮説はあるものの、まだあまりよくわかっていない。心理学では抽象的な仮説レベルで十分、あるいはそれ以上検証不可能なのであるが、コンピュータは残酷なまでに明文化を求め、その結果心理学がこの問題について解釈できた領域はそれほど広くなかったという事実が明らかとなってしまった。それはともかくとして、心理学では**一般化の一般化**[^5]、**メタ認知**[^6]
とよばれる概念群が学習の本質に近いと思われる。ここで対象としている学習とは「ウサギはネズミの一種じゃないんだね」とか「今日は新しいことを憶えた」というような自分の中で新しいルールを作り出す能力のことで、手書き文字認識に見られるような既存のパラメータの調整戦略や効率のよい問題解決法の探索戦略のことではない。したがってニューロネットワークによるパターン認識も、SOARや適応的プロダクションシステム[^7]もあまり役に立たないことになる。  

一般化の一般化を自動車を例に考えてみよう。子供が始めて自動車を見たとき、それが自動車という名前を持つことは親から教えてもらう。次に子供は町を走る車は形が違い、色が違い、大きさが違っているが、どれも自動車と呼ばれることを発見する。このとき子供の中では自動車に共通の特徴を抽出し、一般的な『自動車』の概念が形作られる。これが一般化である。こうした手法を一歩引いて観察すると一般化操作自体も一般化できることが発見される。自分を観察するもう一人の自分、といってもよいかもしれない。こうした心の働きなしにはルール形成はできないだろう。しかしそれがどんなルールなのかはわかっていない。  

実は既存の人工知能が「ルールを作り出せない」ということが意味することはかなり重要である。たとえば研究者がさまざまな問題を解くアルゴリズムを考え出し人工知能がそれによってさまざまな問題を解決したとしても、それはあらかじめ知っている方法で問題を機械的に解いたということ以上の意味はない。むしろ我々が本当に知りたいのは研究者がどうやってそのアルゴリズムに到達したのか、である。人間は問題を提示されてから解決する方法を**考えつく**のであって、すでに知っている解法を使っているだけではない。ここに進歩可能な人間と進歩不可能な人工知能の決定的な差が見られるといってもいいだろう。将来誰かが新しい知能のアルゴリズムを考案したら「そのアルゴリズムは自分自身のようなアルゴリズムを自発的に考えつく能力があるか」ということに留意して観察してほしい。   

### 脳らしさから心らしさへ

人工知能研究は心の研究であり、また脳神経の研究であるという側面を持っている。これまで述べてきたように研究者たちは脳や心をめぐって仮説をたて、あるいは純数学的モデルを考案し、実験-解析を繰り返してプログラムを作り上げてきた[^8][^9] 。 さらに近年、自然言語の解釈や擬人インタフェースには感情が必要であるという見方が再び注目されているが9、それらの試みは関数や膨大なIF-THENルール、すなわち規則で感情を表現できるという立場にたっている。しかしこのような行動心理学的なアプローチは基本的に低い次元の感情を表現するのに適した方法であって、好奇心、創作など高度で記述不可能な精神活動をプログラム化できないという根本的問題を解決できないだろう。  

結局科学的手法であるがゆえに客観的に検証できない領域には目を向けることはできず、結果として人工知能研究は**脳らしさの追求**にとどまってしまったのではないだろうか？そこにはユーモアや芸術、人を楽しませること、なごませることなどが存在する余地はない。ところが我々がのぞむ人と話す機械にとってそれらは最も重要な要素なのである。ゆえに我々のメインテーマは**検証不可能なブラックボックスの中身を記述すること**であることが明らかとなる。言葉を変えればそれは***心らしさ***の追求なのである。そして検証不可能であるがゆえに、あらゆるモデルにとってモデルの科学的正当性や必然性は無意味となり、唯一の尺度『それに接したひとがどれだけ人間らしさを感じられたか』をもって評価される。かといってチューリングテストを人工無脳に用いるのは間違いである。人工知能の研究者J. Weizenbaum[^10]が作ったElizaと呼ばれるプログラムは、このテストで高い得点をマークした。Elizaはきわめて単純な構造の英語版の人工無脳であり、カウンセラーとして多くの人の人生相談を聞き、それを癒したという。人工知能技術はそこには存在しないにもかかわらず。また日本語版の人工無脳たちは我々を楽しませてくれるにもかかわらずチューリングテストでは記録的な低得点をマークするだろう。チューリングテストが目指している『人間らしさ』は概念操作や記号操作に重きをおく｢知的さ｣であって、我々が思う『人間らしさ』とは食い違っているからである。我々が会話していて楽しい相手、気の許せる友人の条件はチューリングテストなどで評価できるだろうか？我々の目的は、笑いやユーモアを感じさせるプログラムの創出なのである。この瞬間、人工知能と人工無脳は違う道を歩み始める。人工無脳は科学的であることをやめアートの一種またはおもちゃの一種になったのである。  

だが、それが心本来の素直な姿なのではないだろうか。  


[^1]: H. L. Dreyfus and S. E. Dreyfus, "MIND OVER MACHINE(邦訳：純粋人工知能批判）" ASCII出版(1987), ISBN 4-87147-366-5
[^2]: E. Feigenbaumはエキスパートシステムでこの問題に直面した。もっともDreyfusに言わせればそれはせいぜい上級者システムなのだそうだが。
[^3]:
[^4]: M. R. Geneseles, N. J. Nicolson, "人工知能基礎論"(古川康一訳), オーム社, 1993
[^5]: ヴィゴツキー,"思考と言語"(柴田義松訳), 明治図書 1962
[^6]: 市川真一編, "認知心理学４ 思考", 東京大学出版 1996, ISBN 4-13-015104-5
[^7]: 辻井潤一, 安西祐一郎, "機械の知 人間の知" 東京大学出版 1988, ISBN 4-13-013070-6
[^8]: S. Williams,"ARGUING A.I. (邦訳:人工知能のパラドックス)" 工学図書(2004), ISBN4-7692-0465-5
[^9]: 岡田直行, "自然言語理解には情緒的機能も必要", 電子情報通信学会誌 70[9] 897-902 (1987)
[^10]: J. Weizenbaum, "ELIZA--A Computer Program For the Study of Natural Language Communication Between Man and Machine", Commun. ACM 10[1] 36-45(1966)